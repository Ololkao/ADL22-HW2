{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hykao/miniconda3/envs/adl-hw2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swag Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swag = load_dataset(\"swag\", \"regular\", cache_dir=\"./swag_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swag[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './swag/'\n",
    "swag_train = pd.read_csv(os.path.join(data_path, 'train.csv'), index_col=0)\n",
    "swag_val   = pd.read_csv(os.path.join(data_path, 'val.csv'), index_col=0)\n",
    "swag_test  = pd.read_csv(os.path.join(data_path, 'test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 73546\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
       "        num_rows: 20006\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3'],\n",
       "        num_rows: 20005\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train, val, test = Dataset.from_pandas(swag_train, preserve_index=False), Dataset.from_pandas(swag_val, preserve_index=False), Dataset.from_pandas(swag_test, preserve_index=False)\n",
    "datasets = DatasetDict()\n",
    "datasets['train'], datasets['val'], datasets['test'] = train, val, test\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': 'lsmdc3090_YOUNG_ADULT-43925',\n",
       " 'fold-ind': 10185,\n",
       " 'startphrase': 'Someone sits at a table in the center of the room. A server',\n",
       " 'sent1': 'Someone sits at a table in the center of the room.',\n",
       " 'sent2': 'A server',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'crosses a courtyard at the foot of the steps.',\n",
       " 'ending1': 'hands the table to someone.',\n",
       " 'ending2': 'reads the name of the television.',\n",
       " 'ending3': 'sets down a napkin and silverware.',\n",
       " 'label': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"val\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {}\n",
    "data_files[\"train\"] = \"train.json\"\n",
    "data_files[\"valid\"] = \"valid.json\"\n",
    "extension = data_files[\"train\"].split('.')[-1]\n",
    "raw_datasets = load_dataset(extension, data_files=data_files)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swag formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def swag_formatter():\n",
    "    folder = \"dataset/\"\n",
    "    corpus = json.load(open(f\"{folder}context.json\"))\n",
    "    train = json.load(open(f\"{folder}train.json\"))\n",
    "    valid = json.load(open(f\"{folder}valid.json\"))\n",
    "    test = json.load(open(f\"{folder}test.json\"))\n",
    "    save_keys = ['id', 'question', 'paragraphs', 'relevant']\n",
    "    ending_names = [f\"ending{i}\" for i in range(4)]\n",
    "    \n",
    "    for idx, data in enumerate(['train', 'valid', 'test']):\n",
    "        results = []\n",
    "        for element in eval(data):\n",
    "            pairs = {}\n",
    "            for key in save_keys:\n",
    "                if key == 'relevant':\n",
    "                    if idx != 2:\n",
    "                        pairs['label'] = element['paragraphs'].index(element[key])\n",
    "                    else:\n",
    "                        pairs['label'] = 0\n",
    "                elif key == 'paragraphs':\n",
    "                    for i, num in enumerate(element[key]):\n",
    "                        pairs[ending_names[i]] = corpus[num]\n",
    "                elif key == 'question':\n",
    "                    pairs['sent1'] = element[key]\n",
    "                    pairs['sent2'] = ''\n",
    "                else:\n",
    "                    pairs['video-id'] = element[key]\n",
    "            results.append(pairs)\n",
    "        json_obj = json.dumps(results, indent=2, ensure_ascii=False)\n",
    "        with open(f\"{folder}swag_{data}.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(json_obj)\n",
    "    \n",
    "swag_formatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (/home/hykao/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "100%|██████████| 2/2 [00:00<00:00, 46.05it/s]\n"
     ]
    }
   ],
   "source": [
    "squad_v2 = False\n",
    "SQuAD = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQuAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQuAD[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQuAD[\"train\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data_path = './SQuAD/'\n",
    "SQuAD_train = json.load(open(os.path.join(data_path, 'train-v1.1.json')))\n",
    "SQuAD_valid = json.load(open(os.path.join(data_path, 'dev-v1.1.json')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = json.dumps(SQuAD_valid, indent=2)\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQuAD_train[\"data\"][0][\"paragraphs\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQuAD formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "valid\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "folder = \"dataset/\"\n",
    "corpus = json.load(open(f\"{folder}context.json\"))\n",
    "train = json.load(open(f\"{folder}train.json\"))\n",
    "valid = json.load(open(f\"{folder}valid.json\"))\n",
    "test = json.load(open(f\"{folder}test.json\"))\n",
    "\n",
    "def squad_formatter():\n",
    "    save_keys = ['id', 'question', 'context', 'answers']\n",
    "    for idx, data in enumerate(['train', 'valid', 'test']):\n",
    "        print(data)\n",
    "        results = []\n",
    "        for element in eval(data):\n",
    "            pairs = {}\n",
    "            for key in save_keys:\n",
    "                if key == 'answers':\n",
    "                    if idx != 2:\n",
    "                        new_dict = {}\n",
    "                        for k, v in element[key[:-1]].items():\n",
    "                            if k != \"text\":\n",
    "                                new_dict[\"answer_\" + k] = [v]\n",
    "                            else:\n",
    "                                new_dict[k] = [v]\n",
    "                        pairs[key] = new_dict\n",
    "                elif key == 'context':\n",
    "                    if idx != 2:\n",
    "                        pairs[key] = corpus[element['relevant']]\n",
    "                    else:\n",
    "                        pairs[key] = corpus[element['paragraphs'][-1]]\n",
    "                else:\n",
    "                    pairs[key] = element[key]\n",
    "            results.append(pairs)\n",
    "        json_obj = json.dumps(results, indent=2, ensure_ascii=False)\n",
    "        with open(f\"{folder}squad_{data}.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(json_obj)\n",
    "    \n",
    "squad_formatter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 95.6132\n"
     ]
    }
   ],
   "source": [
    "# for swag evaluation\n",
    "import json\n",
    "valid = json.load(open(\"dataset/squad_valid.json\")) # validation\n",
    "test = json.load(open(\"format_test.json\")) # prediction\n",
    "\n",
    "total = len(valid)\n",
    "correct = 0\n",
    "for i, element in enumerate(test):\n",
    "    correct += element['context'] == valid[i]['context']\n",
    "print(f\"accuracy: {(correct/total*100):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match: 81.2230\n"
     ]
    }
   ],
   "source": [
    "# for squad evaluation\n",
    "ans_dict = {}\n",
    "for element in valid:\n",
    "    ans_dict[element['id']] = element['answers']['text'][0]\n",
    "# json_obj = json.dumps(ans_dict, ensure_ascii=False, indent=2)\n",
    "# with open(\"ground_truths.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "#     file.write(json_obj)\n",
    "\n",
    "correct = 0\n",
    "total = len(ans_dict)\n",
    "pred = json.load(open(\"output/valid_qa/predict_predictions.json\"))\n",
    "for key, val in pred.items():\n",
    "    if ans_dict[key] == val:\n",
    "        correct += 1\n",
    "print(f\"exact_match: {(correct/total*100):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "\n",
    "df_pred = pd.read_json(\"output/test_qa21/predict_predictions.json\", typ=\"series\").reset_index()\n",
    "df_pred.columns = ['id', 'answer']\n",
    "df_pred.to_csv(\"submit.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d58f4df959ea32ebaed8116792aec46a7c442b2256bec5500f2c868fffa656e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
